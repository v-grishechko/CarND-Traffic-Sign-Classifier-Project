{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Build a Traffic Sign Recognition Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "* Load the data set (see below for links to the project data set)\n",
    "* Explore, summarize and visualize the data set\n",
    "* Design, train and test a model architecture\n",
    "* Use the model to make predictions on new images\n",
    "* Analyze the softmax probabilities of the new images\n",
    "* Summarize the results with a written report\n",
    "\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./writeup_assets/data_set.png \"Visualization\"\n",
    "[image2]: ./writeup_assets/grayscale.png \"Grayscaling\"\n",
    "[image3]: ./writeup_assets/random_rotation.png \"Random Noise\"\n",
    "[image4]: ./writeup_assets/project_transform.png \"Random project transform\"\n",
    "[sign1]: ./new_signs/1.png \"Traffic Sign 1\"\n",
    "[sign2]: ./new_signs/2.png \"Traffic Sign 2\"\n",
    "[sign3]: ./new_signs/3.png \"Traffic Sign 3\"\n",
    "[sign4]: ./new_signs/4.png \"Traffic Sign 4\"\n",
    "[sign5]: ./new_signs/5.png \"Traffic Sign 5\"\n",
    "[data_set_balanced]: ./writeup_assets/data_set_balanced.png \"Balanced data set\"\n",
    "[permanet]: ./writeup_assets/permanet.png \"Permanet\"\n",
    "\n",
    "---\n",
    "\n",
    "###Data Set Summary & Exploration\n",
    "\n",
    "####1. Basic summary of the data set. \n",
    "\n",
    "I used the NumPy library to calculate summary statistics of the traffic\n",
    "signs data set:\n",
    "\n",
    "* The size of training set is **12630**\n",
    "* The size of the validation set is **4410**\n",
    "* The size of test set is **34799**\n",
    "* The shape of a traffic sign image is **(32, 32, 3)**\n",
    "* The number of unique classes/labels in the data set is **43**\n",
    "\n",
    "####2. Include an exploratory visualization of the dataset.\n",
    "\n",
    "Here is an exploratory visualization of the data set. It's bar chart show distribution of all labels and all data set types.\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "###Design and Test a Model Architecture\n",
    "\n",
    "####1. Data should be preprocessed for neural network. By this [paper](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf) I make **pipline**:\n",
    "\n",
    "1. Add augumented images. Count of certain labels is unbalanced. Therefore we need add some augumented data in dataset. I choose projection transform and rotation of images.\n",
    "![alt text][image3]\n",
    "![alt text][image4]\n",
    "    \n",
    "2. Covert images to gray color. Rgb color in this neural network is redundant.\n",
    "![alt_text][image2]\n",
    "\n",
    "3. Normalize images. Neural network learn faster on normalized dataset.\n",
    "\n",
    "Now train data set more balanced. \n",
    "\n",
    "New size of train data set: **51690**.\n",
    "\n",
    "![alt_text][data_set_balanced]\n",
    "\n",
    "\n",
    "####2. Describe what your final model architecture looks like including model type, layers, layer sizes, connectivity, etc.) Consider including a diagram and/or table describing the final model.\n",
    "\n",
    "My final model consisted of the following layers:\n",
    "\n",
    "| Layer         \t\t|     Description\t        \t\t\t    \t| \n",
    "|:---------------------:|:---------------------------------------------:| \n",
    "| Input         \t\t| 32x32x3 RGB image   \t\t\t\t\t\t\t| \n",
    "| Convolution 5x5    \t| 1x1 stride, same padding, outputs 32x32x32 \t|\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling\t      \t| 2x2 stride,  outputs 16x16x32 \t\t\t\t|\n",
    "| Convolution 5x5\t    | 1x1 stride, same padding, outputs 16x16x64    |\n",
    "| RELU                  |                                               |\n",
    "| Max poooling          | 2x2 stride, outputs 8x8x64                    |\n",
    "| Convolution 5x5\t\t| 1x1 stride, same padding, outputs 8x8x128.    |\n",
    "| RELU\t\t\t\t\t|\t\t\t\t\t\t\t\t\t\t\t\t|\n",
    "| Max pooling           | 2x2 stride, outputs 4x4                       |\n",
    "| Concat                | Concat pooling layers, outputs 3584           |\n",
    "| Dropout               | 0.7 probability                               |\n",
    "| Fully connected layer | Fully connected layer, outputs 240            |\n",
    "| Dropout               | 0.7 probability                               |\n",
    "| Out                   | Outputs 43                                    |\n",
    "\n",
    "\n",
    "Used model from [paper](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf).\n",
    "\n",
    "![permanet](./permanet.png)\n",
    "\n",
    "\n",
    "####3. Describe how you trained your model. The discussion can include the type of optimizer, the batch size, number of epochs and any hyperparameters such as learning rate.\n",
    "\n",
    "Params of neural network:\n",
    "\n",
    "| Param                 |    Value                                      |\n",
    "|:---------------------:|:---------------------------------------------:|\n",
    "| Batch size            | 128                                           |\n",
    "| Epochs                | 15                                            |\n",
    "| Learning rate         | 0.0009                                        |\n",
    "| Keep probility        | 0.5                                           |\n",
    "| Type of optimizer     | Adam optimizer                                |\n",
    "\n",
    "This params I found emperically. \n",
    "\n",
    "Model trained on AWS instance on Tesla M60 GPU.\n",
    "\n",
    "####4. Describe the approach taken for finding a solution and getting the validation set accuracy to be at least 0.93. \n",
    "\n",
    "My final model results were:\n",
    "* validation set accuracy of 94.9%\n",
    "* test set accuracy of 94%\n",
    "\n",
    "If an iterative approach was chosen:\n",
    "\n",
    "** What was the first architecture that was tried and why was it chosen? **\n",
    "\n",
    "First architecture choosen LeNet architecture. This architecture choosen, because it used simple and effective neural network. It good architecture for prototyping and tuning.\n",
    "\n",
    "** What were some problems with the initial architecture?**\n",
    "\n",
    "LeNet neural network produce accuracy near 85%. It's good but not enough.\n",
    "\n",
    "** How was the architecture adjusted and why was it adjusted? Typical adjustments could include choosing a different model architecture, adding or taking away layers (pooling, dropout, convolution, etc), using an activation function or changing the activation function. One common justification for adjusting an architecture would be due to overfitting or underfitting. A high accuracy on the training set but low accuracy on the validation set indicates over fitting; a low accuracy on both sets indicates under fitting.**\n",
    "\n",
    "After unsuccessful attempts of tuning params of LeNet I started read [paper](http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf). This paper have description of _Permanet_ neural network and some tips and tricks for data preprocessing. After this I started experiment with neural network _Permanet_ and augumentation of images. This neural network has interesting feature. Layers of this network not connected sequentially. Feature was shown at Permanet picture. I made architecture how on picture and start experimenting with params of layers (count of neurons, dropout propability, kernel size and e.t.c). And after all I come to params which showed at previous tables.\n",
    "\n",
    "** Which parameters were tuned? How were they adjusted and why? **\n",
    "\n",
    "Tuned general hypoparameters:\n",
    "    1. Batch size             128                                           \n",
    "    2. Epochs                 15                                           \n",
    "    3. Learning rate          0.0009                                         \n",
    "    4. Keep probility         0.5                                           \n",
    "    5. Type of optimizer      Adam optimizer  \n",
    "\n",
    "Params founded emperically. Sometimes it was a random experiments. Also help a lot the _Tensorboard_. I logged some params of neural network and see graph of neural network and distribution of graphs of weights, biases.\n",
    "\n",
    "**What are some of the important design choices and why were they chosen? For example, why might a convolution layer work well with this problem? How might a dropout layer help with creating a successful model?**\n",
    "\n",
    "Convolution layers the best choice for image recogntion. Because this layers have ability to recognize some low features of images (straight lines, curve lines, and e.t.c) and grow to more complicated features. \n",
    "\n",
    "Dropout help with overfitting layes. Sometimes neural network overfitted on some images and dropout layer resolve this issue.\n",
    "\n",
    "If a well known architecture was chosen:\n",
    "\n",
    "** What architecture was chosen? **\n",
    "\n",
    "Permanet\n",
    "\n",
    "** Why did you believe it would be relevant to the traffic sign application? **\n",
    "\n",
    "Results of recognition of new images approve. This architecture can be used at recognition of traffic signs.\n",
    "\n",
    "###Test a Model on New Images\n",
    "\n",
    "####1. Choose five German traffic signs found on the web.\n",
    "\n",
    "Here are five German traffic signs that I found on the web and at photo editor I resize this images to 32x32 size.\n",
    "\n",
    "![alt text][sign1] ![alt text][sign2] ![alt text][sign3] ![alt text][sign4] ![alt text][sign5]\n",
    "\n",
    "\n",
    "####2. Discuss the model's predictions on these new traffic signs.\n",
    "\n",
    "Here are the results of the prediction:\n",
    "\n",
    "| Image\t\t\t                          |     Prediction\t        \t\t\t\t\t| \n",
    "|:---------------------------------------:|:-------------------------------------------:| \n",
    "| Right-of-way at the next intersection   | Right-of-way at the next intersection   \t|\n",
    "| Speed limit (30km/h)     \t\t\t      | Speed limit (30km/h) \t\t\t\t\t\t|\n",
    "| Priority road\t\t\t\t\t          | Priority road\t\t\t\t\t\t\t\t|\n",
    "| Keep right      \t\t                  | Keep right\t\t\t\t\t \t\t\t\t|\n",
    "| Turn left head\t\t\t              | Turn left head      \t\t\t\t\t\t|\n",
    "\n",
    "The model was able to correctly guess 5 of the 5 traffic signs, which gives an accuracy of 100%. It's very good result of recognition.\n",
    "\n",
    "####3. Describe how certain the model is when predicting on each of the five new images by looking at the softmax probabilities for each prediction. Provide the top 5 softmax probabilities for each image along with the sign type of each probability.\n",
    "\n",
    "```\n",
    "------------------------------------\n",
    "Recognize: Right-of-way at the next intersection\n",
    "\n",
    "Right-of-way at the next intersection: 100.00%\n",
    "Beware of ice/snow: 0.00%\n",
    "Double curve: 0.00%\n",
    "Speed limit (80km/h): 0.00%\n",
    "Slippery road: 0.00%\n",
    "------------------------------------\n",
    "Recognize: Speed limit (30km/h)\n",
    "\n",
    "Speed limit (30km/h): 86.27%\n",
    "Speed limit (50km/h): 13.73%\n",
    "Speed limit (80km/h): 0.00%\n",
    "End of speed limit (80km/h): 0.00%\n",
    "Stop: 0.00%\n",
    "------------------------------------\n",
    "Recognize: Priority road\n",
    "\n",
    "Priority road: 100.00%\n",
    "Roundabout mandatory: 0.00%\n",
    "No passing: 0.00%\n",
    "No vehicles: 0.00%\n",
    "End of no passing by vehicles over 3.5 metric tons: 0.00%\n",
    "------------------------------------\n",
    "Recognize: Keep right\n",
    "\n",
    "Keep right: 100.00%\n",
    "Speed limit (20km/h): 0.00%\n",
    "Speed limit (30km/h): 0.00%\n",
    "Speed limit (50km/h): 0.00%\n",
    "Speed limit (60km/h): 0.00%\n",
    "------------------------------------\n",
    "Recognize: Turn left ahead\n",
    "\n",
    "Turn left ahead: 100.00%\n",
    "Keep right: 0.00%\n",
    "No passing: 0.00%\n",
    "No vehicles: 0.00%\n",
    "Beware of ice/snow: 0.00%\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
